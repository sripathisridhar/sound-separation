{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/s/ss645/sound-separation/')\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from models.train.data_io import read_lines_from_file\n",
    "from models.train import mixit\n",
    "import tensorflow.compat.v1 as v1\n",
    "from models.train.data_io import wavs_to_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking TensorFlow installation...\n",
      "2022-09-27 14:16:47.099780: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-09-27 14:16:47.099924: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login-1): /proc/driver/nvidia/version does not exist\n",
      "tf.Tensor(-1800.4105, shape=(), dtype=float32)\n",
      "TensorFlow is working, starting training...\n",
      "Start time : 14:16:47\n",
      "INFO:tensorflow:Params: dict_values([8, 1, 16000])\n",
      "INFO:tensorflow:{'feature_spec': {'receiver_audio': FixedLenFeature(shape=[1, 16000], dtype=tf.float32, default_value=None), 'source_images': FixedLenFeature(shape=[8, 1, 16000], dtype=tf.float32, default_value=None)}, 'inference_spec': {'receiver_audio': FixedLenFeature(shape=[1, None], dtype=tf.float32, default_value=None)}, 'hparams': HParams(mix_weights_type='pred_source', signal_names=['mix1_background', 'mix1_foreground_1', 'mix1_foreground_2', 'mix1_foreground_3', 'mix2_background', 'mix2_foreground_1', 'mix2_foreground_2', 'mix2_foreground_3'], signal_types=['source', 'source', 'source', 'source', 'source', 'source', 'source', 'source'], sr=16000.0, lr=0.0001, lr_decay_steps=2000000, lr_decay_rate=0.5, learn_basis=True, num_coeffs=256, ws=0.0025, hs=0.00125), 'io_params': {'parallel_readers': 512, 'num_samples': 160000}, 'input_data_train': '/research/mc232/sound_datasets/tag-new/audio/train_example_list.txt', 'input_data_eval': '/research/mc232/sound_datasets/tag-new/audio/validation_example_list.txt', 'model_dir': '/research/mc232/models/owser/sound_separation/mixit/tag/2022-09-27_14-16-47', 'train_batch_size': 6, 'eval_batch_size': 6, 'train_steps': 200, 'eval_suffix': 'validation', 'eval_examples': 800, 'save_checkpoints_secs': 60, 'save_summary_steps': None, 'keep_checkpoint_every_n_hours': 4, 'write_inference_graph': True, 'randomize_training': True}\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/research/mc232/models/owser/sound_separation/mixit/tag/2022-09-27_14-16-47', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 60, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 4, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 60.\n",
      "WARNING:tensorflow:From /home/s/ss645/miniconda3/envs/separation/lib/python3.10/site-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "2022-09-27 14:18:03.383432: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-09-27 14:18:03.383557: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login-1): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /home/s/ss645/sound-separation/models/train/data_io.py:303: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2022-09-27 14:18:58.292050: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /research/mc232/models/owser/sound_separation/mixit/tag/2022-09-27_14-16-47/model.ckpt.\n",
      "INFO:tensorflow:/research/mc232/models/owser/sound_separation/mixit/tag/2022-09-27_14-16-47/model.ckpt-0.meta\n",
      "INFO:tensorflow:12300\n",
      "INFO:tensorflow:/research/mc232/models/owser/sound_separation/mixit/tag/2022-09-27_14-16-47/model.ckpt-0.data-00000-of-00001\n",
      "INFO:tensorflow:121100\n",
      "INFO:tensorflow:/research/mc232/models/owser/sound_separation/mixit/tag/2022-09-27_14-16-47/model.ckpt-0.index\n",
      "INFO:tensorflow:121100\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "2022-09-27 14:20:01.969042: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24572928 exceeds 10% of free system memory.\n",
      "2022-09-27 14:20:02.163478: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24572928 exceeds 10% of free system memory.\n",
      "2022-09-27 14:20:02.199072: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24572928 exceeds 10% of free system memory.\n",
      "2022-09-27 14:20:02.209343: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 49145856 exceeds 10% of free system memory.\n",
      "2022-09-27 14:20:02.301023: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 49145856 exceeds 10% of free system memory.\n",
      "models/neurips2020_mixit/run_train_model_on_fuss.sh: line 39: 21918 Killed                  python3 ${SCRIPT_PATH}/train_model_on_fuss.py -dd=${TAG_DIR} -md=${OUTPUT_DIR}\n",
      "Start time: 14:16:47, installation end time: 14:20:18\n"
     ]
    }
   ],
   "source": [
    "!bash models/neurips2020_mixit/run_train_model_on_fuss.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4988637\n"
     ]
    }
   ],
   "source": [
    "audio_dir = '/research/mc232/sound_datasets/tag-new/audio/'\n",
    "file_list = glob(join(audio_dir, '*/*/*/*.wav'))\n",
    "print(len(file_list))\n",
    "\n",
    "with open(join(audio_dir, 'train_example_list.txt'), 'w') as f:\n",
    "    for file in file_list[:100]:\n",
    "        f.write(file)\n",
    "\n",
    "with open(join(audio_dir, 'validation_example_list.txt'), 'w') as f:\n",
    "    for file in file_list[100:200]:\n",
    "        f.write(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(audio_dir, 'train_example_list.txt'), 'r') as f:\n",
    "    lines = f.readlines()\n",
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'receiver_audio': <tf.Tensor: shape=(3, 1, 16000), dtype=float32, numpy=\n",
       " array([[[-0.02255249, -0.04876709, -0.05441284, ..., -0.17559814,\n",
       "          -0.10534668, -0.10916138]],\n",
       " \n",
       "        [[-0.03451538, -0.03768921, -0.03683472, ..., -0.05770874,\n",
       "          -0.04794312, -0.04370117]],\n",
       " \n",
       "        [[ 0.11172485,  0.10140991,  0.10397339, ...,  0.39575195,\n",
       "           0.3993225 ,  0.41448975]]], dtype=float32)>,\n",
       " 'source_images': <tf.Tensor: shape=(3, 1, 1, 16000), dtype=float32, numpy=\n",
       " array([[[[-0.02255249, -0.04876709, -0.05441284, ..., -0.17559814,\n",
       "           -0.10534668, -0.10916138]]],\n",
       " \n",
       " \n",
       "        [[[-0.03451538, -0.03768921, -0.03683472, ..., -0.05770874,\n",
       "           -0.04794312, -0.04370117]]],\n",
       " \n",
       " \n",
       "        [[[ 0.11172485,  0.10140991,  0.10397339, ...,  0.39575195,\n",
       "            0.3993225 ,  0.41448975]]]], dtype=float32)>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavs_to_dataset(file_list[:100], 3, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuss_dir = '/research/mc232/sound_datasets/fuss_dev/ssdata'\n",
    "with open(join(fuss_dir, 'validation_example_list.txt'), 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['validation/example0000.wav\\tvalidation/example0000_sources/background0_sound.wav\\n',\n",
       " 'validation/example0001.wav\\tvalidation/example0001_sources/background0_sound.wav\\tvalidation/example0001_sources/foreground0_sound.wav\\n',\n",
       " 'validation/example0002.wav\\tvalidation/example0002_sources/background0_sound.wav\\tvalidation/example0002_sources/foreground0_sound.wav\\tvalidation/example0002_sources/foreground1_sound.wav\\tvalidation/example0002_sources/foreground2_sound.wav\\n',\n",
       " 'validation/example0003.wav\\tvalidation/example0003_sources/background0_sound.wav\\tvalidation/example0003_sources/foreground0_sound.wav\\tvalidation/example0003_sources/foreground1_sound.wav\\tvalidation/example0003_sources/foreground2_sound.wav\\n',\n",
       " 'validation/example0004.wav\\tvalidation/example0004_sources/background0_sound.wav\\tvalidation/example0004_sources/foreground0_sound.wav\\tvalidation/example0004_sources/foreground1_sound.wav\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('separation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9da2f7b74d223542bf4dfeb4a3cdeb3f315584c82706e4e8ce59d9c198a8c8c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
